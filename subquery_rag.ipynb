{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\dev\\simple-rag\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms import LlamaCPP\n",
    "\n",
    "# model_url = \"https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q4_K_M.gguf\"\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    # model_url=\"./llm/zephyr-7b-beta.Q4_K_M.gguf\",\n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path=\"./llm/llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=256,\n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=3900,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 1},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    embed_model=embed_model, \n",
    "    callback_manager=callback_manager,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file titled: Grain size strengthening in terms of dislocation density measured by resistivity\n",
      "Storing and Indexing file title: Grain size strengthening in terms of dislocation density measured by resistivity\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "Init query engine and add to qe_tools\n",
      "Loading file titled: [Armstrong] 60 Years of Hall-Petch - Past to Present Nano-Scale Connections\n",
      "Storing and Indexing file title: [Armstrong] 60 Years of Hall-Petch - Past to Present Nano-Scale Connections\n",
      "**********\n",
      "Trace: index_construction\n",
      "**********\n",
      "Init query engine and add to qe_tools\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import chromadb\n",
    "\n",
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "def parse_string(input_string):\n",
    "    parsed_string = input_string.replace(' ', '_')\n",
    "    parsed_string = parsed_string.replace('-', '_')\n",
    "    parsed_string = re.sub(r'[^a-z0-9_]', '', parsed_string.lower())\n",
    "    parsed_string = re.sub(r'(_)\\1+', r'\\1', parsed_string)\n",
    "    \n",
    "    return parsed_string\n",
    "\n",
    "input_dir = \"./ainu_papers/\"\n",
    "supported_files = [\".pdf\", \".csv\", \".docx\", \".txt\", \".epub\", \".hwp\", \".mbox\", \".ppt\", \".pptm\", \".pptx\", \".ipynb\", \".md\"]\n",
    "files = [f for f in glob.glob(f\"{input_dir}**/*\", recursive=True) if f\".{f.split('.')[-1]}\" in supported_files]\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./db\")\n",
    "query_engine_tools = []\n",
    "\n",
    "for file in files:\n",
    "    new = False\n",
    "    title = \" \".join(file.replace(\"\\\\\", \"/\").split(\"/\")[-1].split(\".\")[:-1])\n",
    "    collection_name = parse_string(title)[:63]\n",
    "    print(f\"Loading file titled: {title}\")\n",
    "    try:\n",
    "        chroma_collection = db.get_collection(collection_name)\n",
    "    except:\n",
    "        new = True\n",
    "        documents = SimpleDirectoryReader(input_files=[file]).load_data()\n",
    "        chroma_collection = db.create_collection(collection_name)\n",
    "\n",
    "    print(f\"Storing and Indexing file title: {title}\")\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "    if new:\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "        index = VectorStoreIndex.from_documents(\n",
    "            documents, \n",
    "            storage_context=storage_context, \n",
    "            service_context=service_context,\n",
    "            use_async=True,\n",
    "        )\n",
    "    else:\n",
    "        index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store,\n",
    "        service_context=service_context,\n",
    "        use_async=True,\n",
    "    )\n",
    "        \n",
    "    print(f\"Init query engine and add to qe_tools\")\n",
    "    # Query Data from the persisted index\n",
    "    query_engine = index.as_query_engine()\n",
    "    query_engine_tools.append(\n",
    "        QueryEngineTool(\n",
    "            query_engine=query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=collection_name,\n",
    "                description=f\"A Paper titled: {title}\",\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "subq_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    service_context=service_context,\n",
    "    use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[grain_size_strengthening_in_terms_of_dislocation_density_measur] Q: What are the advantages of using nickel in experimental studies?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;237;90;200m[grain_size_strengthening_in_terms_of_dislocation_density_measur] A:  Nickel has a high stacking fault energy, which makes it suitable for measuring dislocation density by resistivity.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: query\n",
      "    |_CBEventType.QUERY ->  178.281414 seconds\n",
      "      |_CBEventType.TEMPLATING ->  0.0 seconds\n",
      "      |_CBEventType.LLM ->  39.038289 seconds\n",
      "      |_CBEventType.SUB_QUESTION ->  130.008607 seconds\n",
      "        |_CBEventType.QUERY ->  130.007607 seconds\n",
      "          |_CBEventType.RETRIEVE ->  0.599619 seconds\n",
      "            |_CBEventType.EMBEDDING ->  0.552491 seconds\n",
      "          |_CBEventType.SYNTHESIZE ->  129.407988 seconds\n",
      "            |_CBEventType.TEMPLATING ->  0.0 seconds\n",
      "            |_CBEventType.LLM ->  129.397978 seconds\n",
      "            |_CBEventType.LLM ->  129.397978 seconds\n",
      "      |_CBEventType.SYNTHESIZE ->  9.233516 seconds\n",
      "        |_CBEventType.TEMPLATING ->  0.0 seconds\n",
      "        |_CBEventType.LLM ->  9.231398 seconds\n",
      "**********\n",
      " Nickel has a high stacking fault energy, which makes it suitable for measuring dislocation density by resistivity.\n"
     ]
    }
   ],
   "source": [
    "response = subq_engine.query(\"Why Nickel is chosen as material for the experimentation?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub Question 0: What are the advantages of using nickel in the experiment\n",
      "Answer: There are several advantages to using nickel in the experiment:\n",
      "\n",
      "1. Nickel has a high stacking fault energy, which makes it an ideal material for studying dislocation density and its effect on flow stress.\n",
      "2. Electrical resistivity measurements can be used to determine dislocation density up to larger strains than transmission electron microscopy.\n",
      "3. The experiment allows for the measurement of dislocation density in a wider range of grain sizes than previously possible.\n",
      "4. The relationship between dislocation density and flow stress is independent of grain size, deformation temperature, and plastic strain, making it possible to obtain a general equation for the Hall-Petch relation.\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "# iterate through sub_question items captured in SUB_QUESTION event\n",
    "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
    "\n",
    "for i, (start_event, end_event) in enumerate(\n",
    "    llama_debug.get_event_pairs(CBEventType.SUB_QUESTION)\n",
    "):\n",
    "    qa_pair = end_event.payload[EventPayload.SUB_QUESTION]\n",
    "    print(\"Sub Question \" + str(i) + \": \" + qa_pair.sub_q.sub_question.strip())\n",
    "    print(\"Answer: \" + qa_pair.answer.strip())\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
